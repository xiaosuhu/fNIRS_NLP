{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RidgeRegression(nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch implementation of Ridge Regression\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim):\n",
    "        super(RidgeRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "def fisher_z_transform(r):\n",
    "    \"\"\"\n",
    "    Apply Fisher Z transformation to correlation coefficient\n",
    "    \"\"\"\n",
    "    # Clip r to avoid numerical issues\n",
    "    r = np.clip(r, -0.999999, 0.999999)\n",
    "    return 0.5 * np.log((1 + r) / (1 - r))\n",
    "\n",
    "def compute_correlation(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute Pearson correlation and its Fisher Z transformation\n",
    "    \"\"\"\n",
    "    # Convert to numpy if tensors\n",
    "    if torch.is_tensor(y_true):\n",
    "        y_true = y_true.cpu().numpy()\n",
    "    if torch.is_tensor(y_pred):\n",
    "        y_pred = y_pred.cpu().numpy()\n",
    "    \n",
    "    # Compute correlation\n",
    "    correlation = np.corrcoef(y_true, y_pred)[0, 1]\n",
    "    \n",
    "    # Apply Fisher Z transformation\n",
    "    z_score = fisher_z_transform(correlation)\n",
    "    \n",
    "    return correlation, z_score\n",
    "\n",
    "def nested_loocv_ridge_cuda(X_train, y_train, alphas, device, val_split=0.2):\n",
    "    \"\"\"\n",
    "    Perform Ridge Regression for multiple alphas and find the best one.\n",
    "    \n",
    "    - Uses a single training and validation split.\n",
    "    - Reduces computations from O(n_samples Ã— n_alphas) to O(n_alphas).\n",
    "    \n",
    "    Parameters:\n",
    "        X_train (ndarray): Training feature matrix (n_samples, n_features).\n",
    "        y_train (ndarray): Target values (n_samples,).\n",
    "        alphas (list): List of ridge regression regularization parameters.\n",
    "        device (str): 'cuda' or 'cpu'.\n",
    "        val_split (float): Proportion of data to use for validation (default 20%).\n",
    "    \n",
    "    Returns:\n",
    "        float: Best alpha.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_samples = len(y_train)\n",
    "    split_idx = int(n_samples * (1 - val_split))  # Train-validation split index\n",
    "    \n",
    "    # Convert data to PyTorch tensors and move to GPU if available\n",
    "    X_train = torch.FloatTensor(X_train).to(device)\n",
    "    y_train = torch.FloatTensor(y_train).to(device)\n",
    "    \n",
    "    # Split into training and validation sets\n",
    "    X_train_split, X_val_split = X_train[:split_idx], X_train[split_idx:]\n",
    "    y_train_split, y_val_split = y_train[:split_idx], y_train[split_idx:]\n",
    "\n",
    "    mse_alphas = torch.zeros(len(alphas), device=device)\n",
    "    \n",
    "    for j, alpha in enumerate(alphas):\n",
    "        # Compute (X^T X + alpha*I)\n",
    "        XtX = torch.mm(X_train_split.t(), X_train_split)\n",
    "        reg_term = alpha * torch.eye(X_train_split.shape[1], device=device)  # Regularization term\n",
    "        Xty = torch.mm(X_train_split.t(), y_train_split.unsqueeze(1))\n",
    "        \n",
    "        # Solve for ridge regression weights: (X^T X + alpha I)^(-1) X^T y\n",
    "        weights = torch.linalg.solve(XtX + reg_term, Xty)\n",
    "        \n",
    "        # Compute predictions on validation set\n",
    "        y_pred = torch.mm(X_val_split, weights)\n",
    "        \n",
    "        # Compute Mean Squared Error (MSE)\n",
    "        mse = torch.nn.functional.mse_loss(y_pred, y_val_split.unsqueeze(1))\n",
    "        mse_alphas[j] = mse\n",
    "    \n",
    "    # Select the best alpha based on lowest MSE\n",
    "    best_alpha = alphas[torch.argmin(mse_alphas)]\n",
    "    \n",
    "    return best_alpha.item()\n",
    "\n",
    "def time_series_ridge_cv_cuda(X, y, n_splits=5, device='cuda'):\n",
    "    \"\"\"\n",
    "    GPU-accelerated ridge regression with nested cross-validation and correlation analysis\n",
    "    \"\"\"\n",
    "    # Ensure y is 1D\n",
    "    y = y.ravel()\n",
    "    \n",
    "    # Create logarithmically spaced alphas\n",
    "    alphas = torch.logspace(-1, 8, 10).to(device)\n",
    "    \n",
    "    # Initialize TimeSeriesSplit\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    \n",
    "    # Initialize arrays to store results\n",
    "    predictions = np.zeros_like(y)\n",
    "    coefficients = []\n",
    "    alphas_selected = []\n",
    "    correlations = []\n",
    "    z_scores = []\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    for fold, (train_idx, test_idx) in enumerate(tscv.split(X_scaled)):\n",
    "        X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Find best alpha using nested LOOCV\n",
    "        best_alpha = nested_loocv_ridge_cuda(X_train, y_train, alphas, device)\n",
    "        alphas_selected.append(best_alpha)\n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "        y_train_tensor = torch.FloatTensor(y_train).to(device)\n",
    "        X_test_tensor = torch.FloatTensor(X_test).to(device)\n",
    "        \n",
    "        # Solve ridge regression analytically on GPU\n",
    "        XtX = torch.mm(X_train_tensor.t(), X_train_tensor)\n",
    "        reg_term = best_alpha * torch.eye(X_train.shape[1], device=device)\n",
    "        Xty = torch.mm(X_train_tensor.t(), y_train_tensor.unsqueeze(1))\n",
    "        weights = torch.linalg.solve(XtX + reg_term, Xty)\n",
    "        \n",
    "        # Generate predictions\n",
    "        fold_predictions = torch.mm(X_test_tensor, weights).cpu().numpy().ravel()\n",
    "        predictions[test_idx] = fold_predictions\n",
    "        coefficients.append(weights.cpu().numpy().ravel())\n",
    "        \n",
    "        # Compute correlation and Fisher Z score for this fold\n",
    "        fold_corr, fold_z = compute_correlation(y_test, fold_predictions)\n",
    "        correlations.append(fold_corr)\n",
    "        z_scores.append(fold_z)\n",
    "        \n",
    "        print(f\"Fold {fold + 1}:\")\n",
    "        print(f\"  Selected alpha = {best_alpha:.2e}\")\n",
    "        print(f\"  Correlation = {fold_corr:.4f}\")\n",
    "        print(f\"  Fisher Z = {fold_z:.4f}\")\n",
    "    \n",
    "    # Calculate average correlation and Z-score\n",
    "    mean_correlation = np.mean(correlations)\n",
    "    mean_z = np.mean(z_scores)\n",
    "    std_z = np.std(z_scores, ddof=1)  # Sample standard deviation\n",
    "    \n",
    "    # Calculate standard error of mean Z\n",
    "    se_z = std_z / np.sqrt(len(z_scores))\n",
    "    \n",
    "    results = {\n",
    "        'predictions': predictions,\n",
    "        'coefficients': coefficients,\n",
    "        'alphas': alphas_selected,\n",
    "        'correlations': correlations,\n",
    "        'z_scores': z_scores,\n",
    "        'mean_correlation': mean_correlation,\n",
    "        'mean_z': mean_z,\n",
    "        'std_z': std_z,\n",
    "        'se_z': se_z\n",
    "    }\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Fold 1:\n",
      "  Selected alpha = 1.00e-01\n",
      "  Correlation = 0.9998\n",
      "  Fisher Z = 4.5603\n",
      "Fold 2:\n",
      "  Selected alpha = 1.00e-01\n",
      "  Correlation = 0.9998\n",
      "  Fisher Z = 4.6132\n",
      "Fold 3:\n",
      "  Selected alpha = 1.00e-01\n",
      "  Correlation = 0.9998\n",
      "  Fisher Z = 4.5892\n",
      "Fold 4:\n",
      "  Selected alpha = 1.00e-01\n",
      "  Correlation = 0.9998\n",
      "  Fisher Z = 4.5860\n",
      "Fold 5:\n",
      "  Selected alpha = 1.00e-01\n",
      "  Correlation = 0.9998\n",
      "  Fisher Z = 4.6117\n",
      "\n",
      "Summary Statistics:\n",
      "Mean Correlation: 0.9998\n",
      "Mean Fisher Z: 4.5921\n",
      "Standard Error of Z: 0.0097\n",
      "95% CI for Fisher Z: [4.5730, 4.6111]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Check if CUDA is available\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Generate sample data\n",
    "    np.random.seed(42)\n",
    "    X = np.random.randn(4000, 20)  # Design matrix\n",
    "    true_weights = np.random.randn(20)\n",
    "    y = X @ true_weights + np.random.randn(4000) * 0.1  # Neuroimaging data with noise\n",
    "    \n",
    "    # Run the analysis\n",
    "    results = time_series_ridge_cv_cuda(X, y, device=device)\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    print(f\"Mean Correlation: {results['mean_correlation']:.4f}\")\n",
    "    print(f\"Mean Fisher Z: {results['mean_z']:.4f}\")\n",
    "    print(f\"Standard Error of Z: {results['se_z']:.4f}\")\n",
    "    \n",
    "    # Calculate 95% confidence interval for Z\n",
    "    ci_lower = results['mean_z'] - 1.96 * results['se_z']\n",
    "    ci_upper = results['mean_z'] + 1.96 * results['se_z']\n",
    "    print(f\"95% CI for Fisher Z: [{ci_lower:.4f}, {ci_upper:.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fnirs_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
